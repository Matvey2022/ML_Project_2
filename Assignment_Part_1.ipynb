{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Assignment (First Part)\n",
    "##### Name: Matvey Makhnov<br> \n",
    "Task 1: Detection of inconsistencies in flower descriptions in online floristry and delivery platforms is essential for success, customer retention, and satisfaction. Many companies providing online floristry services are increasingly utilizing deep learning solutions to ensure that a flower image displayed on their platform matches the given description or category. <br> <br>To implement a flower classification convolutional neural network (CNN) trained on the Flowers102 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://thor.robots.ox.ac.uk/flowers/102/102flowers.tgz to Flowers_102_Dataset\\flowers-102\\102flowers.tgz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 345M/345M [00:23<00:00, 14.9MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Flowers_102_Dataset\\flowers-102\\102flowers.tgz to Flowers_102_Dataset\\flowers-102\n",
      "Downloading https://thor.robots.ox.ac.uk/flowers/102/imagelabels.mat to Flowers_102_Dataset\\flowers-102\\imagelabels.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 502/502 [00:00<00:00, 252kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://thor.robots.ox.ac.uk/flowers/102/setid.mat to Flowers_102_Dataset\\flowers-102\\setid.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15.0k/15.0k [00:00<00:00, 7.53MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.optim as optim \n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# set a size for our batches \n",
    "train_batch = 32\n",
    "val_batch = 32 \n",
    "test_batch = 32\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.RandomHorizontalFlip(), \n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                          std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "validation_transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                          std=[0.229, 0.224, 0.225])\n",
    "]) \n",
    "\n",
    "\n",
    "data_path = os.path.join('.', 'Flowers_102_Dataset')\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------\n",
    "\n",
    "#dataset = datasets.Flowers102(root = data_path, transform=None, download=True)\n",
    "# set a size for our sets (training, validation, test) \n",
    "#train_size = int(0.8 * len(dataset))\n",
    "#val_size = int(0.1 * len(dataset))\n",
    "#test_size = len(dataset) - (train_size + val_size)\n",
    "#train_dataset, val_dataset, test_dataset =  random_split(dataset, [train_size,val_size,test_size])\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# I want to apply to apply different transforms compositions \n",
    "# that is why I'll use next code \n",
    "train_dataset = datasets.Flowers102(root = data_path, split=\"train\", transform=train_transform, download=True)\n",
    "val_dataset = datasets.Flowers102(root = data_path, split=\"val\", transform=validation_transform, download=True) \n",
    "test_dataset = datasets.Flowers102(root = data_path, split=\"test\", transform=validation_transform, download=True)\n",
    "\n",
    "\n",
    "\n",
    "#train_dataset, val_dataset, test_dataset =  random_split(dataset, [train_size,val_size,test_size])\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=train_batch,shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=val_batch,shuffle=False)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=test_batch, shuffle=False)\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
